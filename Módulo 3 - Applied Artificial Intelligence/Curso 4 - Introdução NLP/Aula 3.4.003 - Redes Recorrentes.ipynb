{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais Recorrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já sabemos fazer o processamento inicial no texto e construir um classificador, vamos explorar as arquiteturas que permitam processar a sequência de texto mais efetivamente.\n",
    "[GRU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU)\n",
    "[LSTM](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM)\n",
    "\n",
    "Como estes algoritmos são capazes de processar sequências de caracteres, podemos considerar tarefas mais desafiadoras.\n",
    "\n",
    "Considere o problema de **Gerar Texto**.\n",
    "\n",
    "Na aula passada consideramos a tarefa de classificar o \"sentimento\" da sentenca. Agora vamos resolver um problema mais desafiador. \n",
    "\n",
    "Nesta aula vamos modelar o estilo de \"William Shakespeare\", treinando um modelo para que complete poemas \"como Shakespeare os escreveria\".\n",
    "\n",
    "Basicamente, o problema consiste em prever a próxima palavra dado o restante da frase, por exemplo:\n",
    "\n",
    "**x** *= \"That thereby beauty's rose might never\"*, **y** *= \"die\"*\n",
    "\n",
    "\n",
    "**x** *= \"Or who is he so fond will be the\"*, **y** *= \"tomb\"*\n",
    "\n",
    "Para tanto, preparamos um dataset com exemplos de sonetos escritos por Shakespeare:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from fairest creatures we desire increase,', \"that thereby beauty's rose might never die,\", 'but as the riper should by time decease,', 'his tender heir might bear his memory:', 'but thou, contracted to thine own bright eyes,']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "data = open('dataset/text_generation/sonnets.txt').read()\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "print(corpus[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como de costume, precisamos modelar esse problema de maneira que ele seja tratável com uma rede neural.\n",
    "\n",
    "Agora já sabemos utilizar a classe [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) para codificar strings, porém no problema anterior tínhamos que fazer uma classificacão binária de um texto de tamanho máximo constante.\n",
    "\n",
    "Agora, o modelo deve responder com uma palavra, como podemos modificar nossa rede neural para resolver este problema?\n",
    "\n",
    "Antes de modificar a rede neural, vamos pensar como transformaremos o texto bruto no dataset para treinamento do modelo.\n",
    "\n",
    "Uma forma é se aproveitar da funcão [pad_sequence](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) com *padding='pre'* para que normalizemos o tamanho da string de forma que a \"última palavra\" (isto é, a palavra a ser predita pelo modelo) fique na última posicão e seja fácil de se extrair.\n",
    "\n",
    "por exemplo:\n",
    "\n",
    "\n",
    "`\n",
    "\"from fairest creatures we desire increase\" -> (Tokenizer) -> \n",
    "[1, 2, 3, 4, 5, 6] -> (padding) -> [0, 0, 1, 2, 3, 4, 5, 6]`\n",
    "\n",
    "Assim, *y* é facilmente acessível no índice `sentenca[-1]`.\n",
    "\n",
    "Portanto, o primeiro passo é utilizar o tokenizer para que o vocabulário seja definido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#Seu parametro\n",
    "max_vocab_size = \n",
    "\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_vocab_size, lower=True)\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "corpus_seqs = tokenizer.texts_to_sequences(corpus)\n",
    "corpus_seqs[0:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo é organizar nossa base de treinamento. \n",
    "\n",
    "Como queremos que o modelo seja capaz de prever a próxima palavra em qualquer ponto da frase, vamos considerar todas as subfrases possíveis de se formar com cada linha de soneto.\n",
    "\n",
    "Por exemplo, para a frase `\"from fairest creatures we desire increase\"` as seguintes subfrases serão geradas\n",
    "\n",
    "`\n",
    "\"from fairest\"\n",
    "\"from fairest creatures\"\n",
    "\"from fairest creatures we\"\n",
    "\"from fairest creatures we desire\"\n",
    "\"from fairest creatures we desire increase\"\n",
    "`\n",
    "\n",
    "Ou, em sua versão codificada:\n",
    "\n",
    "`\n",
    "[35, 418]\n",
    "[35, 418, 878]\n",
    "[35, 418, 878, 167]\n",
    "[35, 418, 878, 167, 214]\n",
    "[35, 418, 878, 167, 214, 518]\n",
    "`\n",
    "\n",
    "Codifique uma funcao `process_corpus(seqs)` que vai transformar o corpus_seqs definido na célula acima criando as subfrases como descrito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(seqs):\n",
    "    res_seqs = []\n",
    "    #Seu Codigo Aqui\n",
    "    return res_seqs\n",
    "\n",
    "proc_corpus = process_corpus(corpus_seqs)\n",
    "print(proc_corpus[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos fazer o processamento final das sentencas com [padding](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences).\n",
    "\n",
    "\n",
    "O faremos de modo que a \"palavra a ser predita\" fique no último índice, facilitando o processamento posterior quando precisarmos separar a base em \"x\" e \"y\".\n",
    "\n",
    "Note que aqui também devemos determinar o \"tamanho máximo da frase\", que efetivamente vai determinar até quantas palavras no passado o modelo vai olhar para definir a próxima palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Seu parametro\n",
    "max_len = \n",
    "\n",
    "\n",
    "padded_dataset = pad_sequences(proc_corpus, maxlen=max_len + 1, padding='pre', truncating='pre')\n",
    "print(padded_dataset[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos os dados organizados de uma maneira mais palatável para uma rede neural.\n",
    "\n",
    "Diferentemente da rede construída para a tarefa de classificacão de sentimentos, aqui nossa rede neural precisa ter `max_vocab_size` saídas, que efetivamente significa que a saída da rede vai ser uma probabilidade de a próxima palavra ser cada uma das possiblidades em nosso vocábulo.\n",
    "\n",
    "Para o treinamento, é mais indicado que codifiquemos a palavra a ser prevista com um one-hot encoding, assim a saída da rede vai ser uma probabilidade para cada palavra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as ku \n",
    "import numpy as np\n",
    "\n",
    "X = np.array(padded_dataset[:,:-1])\n",
    "y = padded_dataset[:,-1]\n",
    "y = ku.to_categorical(y, num_classes = max_vocab_size)\n",
    "\n",
    "\n",
    "print(X[0:2])\n",
    "print(y[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora sim, o processamento do texto está terminado e podemos treinar nossa rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional, Dropout, LSTM, Dense, Embedding\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "embedding_dim = 100\n",
    "model = Sequential()\n",
    "#Sua Arquitetura\n",
    "\n",
    "# Pick an optimizer\n",
    "optimizer = \n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este modelo pode agora ser utilizado para  prever as próximas palavras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_word(model, frase):\n",
    "    sequences = tokenizer.texts_to_sequences([frase])\n",
    "    padded = pad_sequences(sequences, maxlen=max_len , padding='pre', truncating='pre')\n",
    "    predicted = model.predict_classes(padded)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    return output_word\n",
    "    \n",
    "get_next_word(model, 'please, save me in this')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inclusive, podemos gerar uma sequencia maior de palavras para formar um novo soneto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_words = 50\n",
    "\n",
    "sentence = 'please, save me in this'\n",
    "for i in range(generate_words):\n",
    "    sentence = sentence + \" \" + get_next_word(model, sentence)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para uma determinada entrada, o modelo sempre vai responder a mesma palavra, o que não é interessante. Modifique a funcão `get_next_word` para retornar uma palavra com probabilidade igual à especificada pelo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste diversas possibilidades de arquitetura, com modelos bidirecionais, LSTM e GRUs, quais deles obtém um resultado melhor?\n",
    "\n",
    "\n",
    "Após isso, tente treinar um modelo semelhante usando poemas de [Goncalves Dias](http://www.dominiopublico.gov.br/download/texto/bv000115.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
