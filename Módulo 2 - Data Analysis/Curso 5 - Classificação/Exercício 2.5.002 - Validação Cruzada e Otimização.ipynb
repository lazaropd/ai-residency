{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercicio\n",
    "* Monte uma classificacao utilizando a base da VEL ou SEN\n",
    "* Monte testes de avaliacao de diferentes classificadores considerando:\n",
    "* Busca por hiperparametros (Considere testar parametros de regularizacao)\n",
    "* Busca por features\n",
    "* Utilize um metodo de validacao cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier pipeline test accuracy: 0.872\n",
      "Logistic Regression pipeline test accuracy: 0.867\n",
      "KNN pipeline test accuracy: 0.873\n",
      "Decision Tree pipeline test accuracy: 0.846\n",
      "\n",
      "\n",
      "# Decision Tree - Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best accuracy: 0.893\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.36      0.44        85\n",
      "           1       0.91      0.95      0.93       577\n",
      "\n",
      "    accuracy                           0.88       662\n",
      "   macro avg       0.73      0.66      0.68       662\n",
      "weighted avg       0.86      0.88      0.87       662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Decision Tree - Tuning hyper-parameters for recall_macro\n",
      "\n",
      "Best accuracy: 0.693\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'entropy', 'clf__max_depth': 3, 'clf__min_samples_leaf': 5, 'clf__min_samples_split': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.45      0.44        85\n",
      "           1       0.92      0.92      0.92       577\n",
      "\n",
      "    accuracy                           0.85       662\n",
      "   macro avg       0.68      0.68      0.68       662\n",
      "weighted avg       0.86      0.85      0.86       662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# Decision Tree - Tuning hyper-parameters for precision_macro\n",
      "\n",
      "Best accuracy: 0.770\n",
      "\n",
      "Best params:\n",
      " {'clf__criterion': 'gini', 'clf__max_depth': 5, 'clf__min_samples_leaf': 3, 'clf__min_samples_split': 5}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.39      0.46        85\n",
      "           1       0.91      0.95      0.93       577\n",
      "\n",
      "    accuracy                           0.88       662\n",
      "   macro avg       0.74      0.67      0.70       662\n",
      "weighted avg       0.87      0.88      0.87       662\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ler dados\n",
    "\n",
    "df = pd.read_csv('dataset/evasao.csv')\n",
    "df = df.drop(['DT_INGRESSO_CURSO'], axis=1)\n",
    "\n",
    "X = df.drop(['TP_SITUACAO'], axis=1)\n",
    "y = df['TP_SITUACAO']\n",
    "\n",
    "\n",
    "# reduzir o número de features mantendo apenas as k mais relevantes\n",
    "\n",
    "X = SelectKBest(chi2, k=5).fit_transform(X, y)\n",
    "\n",
    "\n",
    "# testar alguns modelos de forma exploratória\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "pipe_sgd = Pipeline([('scl', StandardScaler()), ('clf', SGDClassifier())])\n",
    "pipe_lr = Pipeline([('scl', StandardScaler()), ('clf', LogisticRegression())])\n",
    "pipe_knn = Pipeline([('scl', StandardScaler()), ('clf', KNeighborsClassifier())])\n",
    "pipe_dt = Pipeline([('scl', StandardScaler()), ('clf', DecisionTreeClassifier())])\n",
    "\n",
    "pipelines = [pipe_sgd, pipe_lr, pipe_knn, pipe_dt]\n",
    "pipe_dict = {0: 'SGD Classifier', 1: 'Logistic Regression', 2: 'KNN', 3: 'Decision Tree'}\n",
    "\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "for idx, val in enumerate(pipelines):\n",
    "    print('%s pipeline test accuracy: %.3f' % (pipe_dict[idx], val.score(X_test, y_test)))\n",
    "\n",
    "\n",
    "# selecionar um modelo para otimizar\n",
    "    \n",
    "pipetree = pipelines[3]\n",
    "pipe = [pipetree]    \n",
    "\n",
    "param_range = [3, 5]\n",
    "grid_params = [{'clf__criterion': ['gini', 'entropy'],\n",
    "                'clf__max_depth': param_range,\n",
    "                'clf__min_samples_leaf': param_range,\n",
    "                'clf__min_samples_split': param_range[1:]\n",
    "              }]\n",
    "\n",
    "\n",
    "scores = ['accuracy', 'recall_macro', 'precision_macro']\n",
    "for score in scores:\n",
    "    \n",
    "    kfolds = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "    cv = kfolds.split(X_train, y_train)\n",
    "\n",
    "    print(\"\\n\\n# Decision Tree - Tuning hyper-parameters for %s\" % score)\n",
    "    gs = GridSearchCV(estimator=pipetree, param_grid=grid_params, scoring=score, cv=cv)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('\\nBest accuracy: %.3f' % gs.best_score_)\n",
    "    print('\\nBest params:\\n', gs.best_params_)\n",
    "\n",
    "    print(\"\\nGrid scores on development set:\")\n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "    print(\"\\nClassification report:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, gs.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'scl', 'clf', 'scl__copy', 'scl__with_mean', 'scl__with_std', 'clf__alpha', 'clf__average', 'clf__class_weight', 'clf__early_stopping', 'clf__epsilon', 'clf__eta0', 'clf__fit_intercept', 'clf__l1_ratio', 'clf__learning_rate', 'clf__loss', 'clf__max_iter', 'clf__n_iter_no_change', 'clf__n_jobs', 'clf__penalty', 'clf__power_t', 'clf__random_state', 'clf__shuffle', 'clf__tol', 'clf__validation_fraction', 'clf__verbose', 'clf__warm_start'])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipelines[0].get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "# SGD - Tuning hyper-parameters for accuracy\n",
      "\n",
      "Best accuracy: 0.871\n",
      "\n",
      "Best params:\n",
      " {'clf__loss': 'modified_huber', 'clf__penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        85\n",
      "           1       0.87      1.00      0.93       577\n",
      "\n",
      "    accuracy                           0.87       662\n",
      "   macro avg       0.44      0.50      0.47       662\n",
      "weighted avg       0.76      0.87      0.81       662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# SGD - Tuning hyper-parameters for recall_macro\n",
      "\n",
      "Best accuracy: 0.887\n",
      "\n",
      "Best params:\n",
      " {'clf__loss': 'modified_huber', 'clf__penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        85\n",
      "           1       0.87      1.00      0.93       577\n",
      "\n",
      "    accuracy                           0.87       662\n",
      "   macro avg       0.44      0.50      0.47       662\n",
      "weighted avg       0.76      0.87      0.81       662\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# SGD - Tuning hyper-parameters for precision_macro\n",
      "\n",
      "Best accuracy: 0.707\n",
      "\n",
      "Best params:\n",
      " {'clf__loss': 'modified_huber', 'clf__penalty': 'l1'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "Classification report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.93      0.58        85\n",
      "           1       0.99      0.81      0.89       577\n",
      "\n",
      "    accuracy                           0.82       662\n",
      "   macro avg       0.70      0.87      0.73       662\n",
      "weighted avg       0.91      0.82      0.85       662\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipetree = pipelines[0] #sgd\n",
    "pipe = [pipetree]    \n",
    "\n",
    "param_range = [3, 5]\n",
    "alphas = [0.0001, 0.01, 1]\n",
    "\n",
    "grid_params = [{'clf__penalty': ['l1', 'l2'],\n",
    "                'clf__loss': ['hinge', 'modified_huber', 'log']#,\n",
    "                #'clf__alpha': alphas\n",
    "              }]\n",
    "\n",
    "\n",
    "scores = ['accuracy', 'recall_macro', 'precision_macro']\n",
    "for score in scores:\n",
    "    \n",
    "    kfolds = StratifiedKFold(n_splits=2, shuffle=True)\n",
    "    cv = kfolds.split(X_train, y_train)\n",
    "\n",
    "    print(\"\\n\\n# SGD - Tuning hyper-parameters for %s\" % score)\n",
    "    gs = GridSearchCV(estimator=pipetree, param_grid=grid_params, scoring=score, cv=cv)\n",
    "    gs.fit(X_train, y_train)\n",
    "    print('\\nBest accuracy: %.3f' % gs.best_score_)\n",
    "    print('\\nBest params:\\n', gs.best_params_)\n",
    "\n",
    "    print(\"\\nGrid scores on development set:\")\n",
    "    means = gs.cv_results_['mean_test_score']\n",
    "    stds = gs.cv_results_['std_test_score']\n",
    "    #for mean, std, params in zip(means, stds, gs.cv_results_['params']):\n",
    "    #    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "    \n",
    "    print(\"\\nClassification report:\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, gs.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
